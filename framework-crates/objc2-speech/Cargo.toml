# This file has been automatically generated by `objc2`'s `header-translator`.
# DO NOT EDIT

[package]
name = "objc2-speech"
version.workspace = true
description = "Bindings to the Speech framework"
edition.workspace = true
rust-version.workspace = true
keywords = ["cocoa", "apple", "framework", "macos", "ios"]
categories.workspace = true
repository.workspace = true
license.workspace = true

[lints]
workspace = true

[dependencies]
block2 = { workspace = true, optional = true, features = ["alloc"] }
objc2 = { workspace = true, features = ["std"] }
objc2-avf-audio = { workspace = true, optional = true, features = [
    "AVAudioBuffer",
    "AVAudioFormat",
] }
objc2-core-media = { workspace = true, optional = true, features = [
    "CMSampleBuffer",
    "objc2",
] }
objc2-foundation = { workspace = true, features = ["alloc"] }

[package.metadata.docs.rs]
default-target = "aarch64-apple-darwin"
rustc-args = ["--cfg", "docsrs"] # Fix cross-crate link to objc2::topics
targets = [
    "aarch64-apple-darwin",
    "x86_64-apple-darwin",
    "aarch64-apple-ios",
    "aarch64-apple-ios-macabi",
    "aarch64-apple-visionos",
]

[features]
default = [
    "std",
    "SFErrors",
    "SFSpeechLanguageModel",
    "SFSpeechRecognitionMetadata",
    "SFSpeechRecognitionRequest",
    "SFSpeechRecognitionResult",
    "SFSpeechRecognitionTask",
    "SFSpeechRecognitionTaskHint",
    "SFSpeechRecognizer",
    "SFTranscription",
    "SFTranscriptionSegment",
    "SFVoiceAnalytics",
    "block2",
    "objc2-avf-audio",
    "objc2-core-media",
]
std = ["alloc"]
alloc = []
block2 = ["dep:block2"]
objc2-avf-audio = ["dep:objc2-avf-audio"]
objc2-core-media = ["dep:objc2-core-media"]

SFErrors = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSString",
]
SFSpeechLanguageModel = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSString",
    "objc2-foundation/NSURL",
    "objc2-foundation/NSValue",
]
SFSpeechRecognitionMetadata = [
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
]
SFSpeechRecognitionRequest = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSString",
    "objc2-foundation/NSURL",
]
SFSpeechRecognitionResult = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSObject",
]
SFSpeechRecognitionTask = [
    "objc2-foundation/NSDate",
    "objc2-foundation/NSError",
]
SFSpeechRecognitionTaskHint = []
SFSpeechRecognizer = [
    "objc2-foundation/NSError",
    "objc2-foundation/NSLocale",
    "objc2-foundation/NSOperation",
    "objc2-foundation/NSSet",
]
SFTranscription = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSString",
]
SFTranscriptionSegment = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSRange",
    "objc2-foundation/NSString",
]
SFVoiceAnalytics = [
    "objc2-foundation/NSArray",
    "objc2-foundation/NSDate",
    "objc2-foundation/NSObject",
    "objc2-foundation/NSValue",
]
